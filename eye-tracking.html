<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üëã&lt;/text&gt;&lt;/svg&gt;">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>Eye-tracking experiment and drift correction &nbsp;|&nbsp;Hi, I‚Äôm Luhang</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="Eye-tracking experiment and drift correction ">
  
  
    <meta property="og:image" content="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üëÅÔ∏è&lt;/text&gt;&lt;/svg&gt;">
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üëã&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üòÄ&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>About</span>
        </div>
      </a>
    
  
    
  
    
  
    
  
    
  
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
      <div class="Header__Icon">
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;üëÅÔ∏è&lt;/text&gt;&lt;/svg&gt;"></span>
      </div>
    
    <h1 class="Header__Title">Eye-tracking experiment and drift correction </h1>
    
      <div class="DateTagBar">
        
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--brown">
            <a href="tag/HCI Research.html">HCI Research</a>
          </span>
        
          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--purple">
            <a href="tag/Machine Learning.html">Machine Learning</a>
          </span>
        
      </div>
    
  </header>
  <article id="https://www.notion.so/2106b074a1a2808cbdd7f32ff7df227b" class="PageRoot"><div id="https://www.notion.so/2106b074a1a28187bc08c0c66bba418e" class="ColorfulBlock ColorfulBlock--BgGray Callout"><div class="Callout__Icon"><div class="Icon">‚ö†Ô∏è</div></div><p class="Callout__Content"><span class="SemanticStringArray"><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorDefault">Unpublished paper (manuscript in preparation). </mark></span><span class="SemanticString"><mark class="SemanticString__Fragment SemanticString__Fragment--HighlightedColor SemanticString__Fragment--ColorDefault"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Please do not share outside the application process. </strong></mark></span></span></p></div><h3 id="https://www.notion.so/2106b074a1a2814388bccb103b49d635" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2106b074a1a2814388bccb103b49d635"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Research background and related works </span></span></h3><div id="https://www.notion.so/2106b074a1a2812f84f4f9a7e493022f" class="Divider"></div><div id="https://www.notion.so/2106b074a1a281d6a4eec0abb3e720ce" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Previous research in corrective methods in eye-tracking data have largely been effective on a case-by-case basis; no single method has been effective at correcting eye-tracking data with all types of reading error present. Current solutions point to default packages capable of correcting specific error types in reading data, but are vulnerable in the presence of other types. </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://link.springer.com/article/10.3758/s13428-021-01554-0">Carr et al. </a></span><span class="SemanticString">proposed ten algorithms for correcting reading error, which are: </span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">attach, chain, cluster, compare, merge, regress, segment, split, stretch, warp</em></span><span class="SemanticString">. However, a number of problems exist for each one. </span></span></p></div><div id="https://www.notion.so/2106b074a1a281479e86f67d1782dc2b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Current methods have not explored using Neural Networks to add an extra classification step in correcting reading data. The motivation of this research directly stems from the outcomes of Carr‚Äôs research and the hypothesis that certain corrective algorithms perform best on different sets of factors and errors present in reading data. </span></span></p></div><h3 id="https://www.notion.so/2106b074a1a281d7ba25d29a733521cb" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2106b074a1a281d7ba25d29a733521cb"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Experiment design</span></span></h3><div id="https://www.notion.so/2106b074a1a281108e16fc8bdb8658c8" class="Divider"></div><ol class="NumberedListWrapper"><li id="https://www.notion.so/2106b074a1a2814d8f91dcf86252bce4" class="NumberedList" value="1"><span class="SemanticStringArray"><span class="SemanticString">Create a </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">synthetic dataset</strong></span><span class="SemanticString"> that simulates different forms of drift phenomena at different levels.</span></span></li><li id="https://www.notion.so/2106b074a1a281dfa3a8e524afdd48b7" class="NumberedList" value="2"><span class="SemanticStringArray"><span class="SemanticString">Determine the best-performing algorithm for each type of error by correcting synthetic data with different levels of drift phenomena.</span></span></li><li id="https://www.notion.so/2106b074a1a281e384a6c229df80992a" class="NumberedList" value="3"><span class="SemanticStringArray"><span class="SemanticString">Process the dataset to fit the input requirement of a Neural Network (NN) with Convolutional layers.</span></span></li><li id="https://www.notion.so/2106b074a1a28123a674dab984dd4f12" class="NumberedList" value="4"><span class="SemanticStringArray"><span class="SemanticString">Run this synthetic dataset through the Convolutional Neural Network (CNN) to classify the most prominent type of error in the trial, then correct the trial with appropriate algorithm.</span></span></li><li id="https://www.notion.so/2106b074a1a281fc9d6ef89212b9d043" class="NumberedList" value="5"><span class="SemanticStringArray"><span class="SemanticString">Compare batch correction quality with and without the CNN classification. </span></span></li><li id="https://www.notion.so/2106b074a1a281ecb096e068bd30051d" class="NumberedList" value="6"><span class="SemanticStringArray"><span class="SemanticString">Collect </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">real eye-tracking data</strong></span><span class="SemanticString"> from participants at Colby College. Make manual corrections to create ‚ÄúGolden Set‚Äù of real data that will be the ground truth. </span></span></li><li id="https://www.notion.so/2106b074a1a281e685d6fa4176e77578" class="NumberedList" value="7"><span class="SemanticStringArray"><span class="SemanticString">Process the the real dataset and the Golden Set fit the input requirements of the CNN. Use it to train the CNN.</span></span></li><li id="https://www.notion.so/2106b074a1a2810da158e801a2c387f4" class="NumberedList" value="8"><span class="SemanticStringArray"><span class="SemanticString">Compare correction accuracies of real dataset with and without classification as an intermediate step, using Golden Set as the baseline. </span></span></li></ol><h3 id="https://www.notion.so/2106b074a1a28120a430cf3970bb93a9" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2106b074a1a28120a430cf3970bb93a9"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Data collection and preparation </span></span></h3><div id="https://www.notion.so/2106b074a1a2815a8b09cae6d90d6497" class="Divider"></div><div id="https://www.notion.so/2106b074a1a281f3aea8cd3b27fae1f8" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I prepared two sets of eye-tracking data for this controlled experiment: synthetic data and real data.</span></span></p></div><div id="https://www.notion.so/2106b074a1a2819dbfb1d69de4570957" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Synthetic dataset creation and best correction algorithms </strong></span></span></p></div><div id="https://www.notion.so/2106b074a1a281108cdcfd252bc5d516" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">My goal was to create a synthetic dataset as close to real reading data as possible, and I chose to focus on four common errors: </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">noise, shift, droop, and offset</strong></span><span class="SemanticString">. For each simulated reading trial of the following text, I found the area of interest (AOI) for each word and added tokens for each AOI, using the </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://github.com/nalmadi/EMIP-Toolkit">EMIP Toolkit</a></span><span class="SemanticString">. </span></span></p></div><div id="https://www.notion.so/2106b074a1a28160bdb2ce14a07acfee" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><div id="https://www.notion.so/2106b074a1a2815eab5be2f3a25c4144" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I continued to employ the EMIP Toolkit to generate fixations around the center of every word, varied by a small distance to the left or right at random, in the passage based on the x and y positions of each AOI, as well as their width and height. The figure below shows synthetically created error types.</span></span></p></div><div id="https://www.notion.so/2106b074a1a281ec91a4f99947c5ba2e" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fed7413d0-d84e-4074-b264-57f425745473%2FUntitled.png?width=384&amp;table=block&amp;id=2106b074-a1a2-81ec-91a4-f99947c5ba2e"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fed7413d0-d84e-4074-b264-57f425745473%2FUntitled.png?width=384&amp;table=block&amp;id=2106b074-a1a2-81ec-91a4-f99947c5ba2e" style="width:384px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/2106b074a1a2812fa6d3d0b0eecb0854" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The next step was to determine which of the algorithms discussed in Carr&#x27;s research was best suited for correcting each type of error. I generated synthetic reading trials with an increasing error probability ranging from 0 to 1. For each trial and for each level of error probability, I applied all ten algorithms and and calculated and visualized the average accuracy for each algorithm. The selected algorithms for each type of error are outlined in table below. </span></span></p></div><div id="https://www.notion.so/2106b074a1a281e68112d9a966844230" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fb4558a87-df57-4304-8b7a-5b8a78f0fb72%2FUntitled.png?width=288&amp;table=block&amp;id=2106b074-a1a2-81e6-8112-d9a966844230"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fb4558a87-df57-4304-8b7a-5b8a78f0fb72%2FUntitled.png?width=288&amp;table=block&amp;id=2106b074-a1a2-81e6-8112-d9a966844230" style="width:288px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/2106b074a1a281de871acd83521011f2" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Real data collection and ‚ÄúGolden Set‚Äù creation</strong></span></span></p></div><div id="https://www.notion.so/2106b074a1a281839e4ae9b9999ee8ea" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">To run human-subjects experiments, I first filed an Institutional Review Boards (IRB) request outlining the experiment protocols and research objectives. Then I sent out invitations for participants from Colby College and presented them for the same text to read during the experiments while tracking their eye movements with eye-tracking camera. I assisted participants with the equipments and camera calibration. </span></span></p></div><div id="https://www.notion.so/2106b074a1a281338bc2dd3881c03dec" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Then I manually corrected the collected data to create a ‚ÄúGolden Set‚Äù, which will be used for evaluating the performance of our NN-based classifier on real-world data. I batched the fixations - visualize 5 or 6 fixations at a time - in order to better see micro patterns in the data. This enabled us to detect things such as vertical drift, which was the most common error that we encountered during the corrections. </span></span></p></div><h3 id="https://www.notion.so/2106b074a1a28197812bcb195b4ce671" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2106b074a1a28197812bcb195b4ce671"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Neural Network Development</span></span></h3><div id="https://www.notion.so/2106b074a1a281f5b97fc821ef5d9129" class="Divider"></div><div id="https://www.notion.so/2106b074a1a281958a4ef64aef530cb3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">The purpose of the NN-based classifier is to predict the dominating error that is present in a reading trial. The 2D features of fixation data points inspired me to remodel the problem of eye-tracking fixation to image processing, which is a widely studied area with developed methodologies. I also prepared two NN models: a simple multi-layer perception (MLP) and another one with a 2D Convolutional layer on top of the MLP. </span></span></p></div><div id="https://www.notion.so/2106b074a1a28158a558cf90f82853f7" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">NN Classification Accuracy</strong></span></span></p></div><div id="https://www.notion.so/2106b074a1a281febba0f4e224ae6679" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I used the synthetic dataset that covers a comprehensive range of error probabilities for each type of error as the training set; for validation purposes, I generated a smaller dataset with only 500 samples that randomly selected the error type and error probabilities. Results shows that the addition of the Convolutional layer significantly improved both the training and validation accuracy. Below is the confusion matrix for the CNN classifier. </span></span></p></div><div id="https://www.notion.so/2106b074a1a281528a73cbc1e0788085" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F7022bea0-0fd2-40da-a1a4-8c8ee6b33fce%2FUntitled.png?width=288&amp;table=block&amp;id=2106b074-a1a2-8152-8a73-cbc1e0788085"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F7022bea0-0fd2-40da-a1a4-8c8ee6b33fce%2FUntitled.png?width=288&amp;table=block&amp;id=2106b074-a1a2-8152-8a73-cbc1e0788085" style="width:288px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><h3 id="https://www.notion.so/2106b074a1a28156a19cf1c0fd03b73e" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2106b074a1a28156a19cf1c0fd03b73e"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Combining CNN-Classifier and Correction Algorithms </span></span></h3><div id="https://www.notion.so/2106b074a1a281ef83b7e2ce890c13df" class="Divider"></div><div id="https://www.notion.so/2106b074a1a28128998ff127fc97fc41" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">This section is the key to my research question: does a intermediate, CNN-based classification step that selects a classification algorithm always improve final correction accuracy?</span></span></p></div><div id="https://www.notion.so/2106b074a1a281da9d6cd44831c648d3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I repeated the process that, for each synthetically generated reading trial with increasing error probability, I run the trial through the ten algorithms, but added an additional evaluation at the end that first feeds the sample into an CNN-based classifier, which predicts the most dominating error present in the sample, selects the algorithm for the specific error and correct it, and computes the correction accuracy. This means each trial will be corrected by all ten correction algorithms and by the algorithm picked by the classifier. The diagram below provides an intuitive visualization to the workflow. The same workflow will be repeated for the real dataset. </span></span></p></div><div id="https://www.notion.so/2106b074a1a28140b377fd6cc06f0857" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fccc7eb35-c7ad-4fc9-a892-1c34ad879a0e%2FUntitled.png?width=432&amp;table=block&amp;id=2106b074-a1a2-8140-b377-fd6cc06f0857"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fccc7eb35-c7ad-4fc9-a892-1c34ad879a0e%2FUntitled.png?width=432&amp;table=block&amp;id=2106b074-a1a2-8140-b377-fd6cc06f0857" style="width:432px"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/2106b074a1a2818f802aeba7f2dba830" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Challenges and workarounds</strong></span></span></p></div><div id="https://www.notion.so/2106b074a1a281a9b1e2ca4e2bc5948e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">My initial findings reveal that when the classification step is added, the correction accuracy outperforms any algorithm when error probability is greater than 0.4. When error probabilities are lower, however, its performance is not significantly better than simpler correction algorithms. </span></span></p></div><div id="https://www.notion.so/2106b074a1a2811cac5ffe8d264a091c" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F6637b124-c0ec-4075-8b6c-b04e2882bd1c%2FUntitled.png?width=480&amp;table=block&amp;id=2106b074-a1a2-811c-ac5f-fe8d264a091c"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F6637b124-c0ec-4075-8b6c-b04e2882bd1c%2FUntitled.png?width=480&amp;table=block&amp;id=2106b074-a1a2-811c-ac5f-fe8d264a091c" style="width:480px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Classifier with correction algorithms on synthetic data, showing that the approach with classifier has weaker performance when error probability is low</span></span></figcaption></figure></div><div id="https://www.notion.so/2106b074a1a281ae8c09f9bf8e07fdfd" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">I found out that this is due to reading trials with small errors being misclassified as ‚Äúno error‚Äù, where the system will no apply a correction algorithm. </span></span></p></div><div id="https://www.notion.so/2106b074a1a2810ebae6f20b6587381c" class="ColumnList"><div id="https://www.notion.so/2106b074a1a281f895d9fc2dfda2d720" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/2106b074a1a281769f33d761a6cb4cbb" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F8f86973c-327b-4fbd-9f7f-42b187af7a9c%2FUntitled.png?width=624&amp;table=block&amp;id=2106b074-a1a2-8176-9f33-d761a6cb4cbb"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F8f86973c-327b-4fbd-9f7f-42b187af7a9c%2FUntitled.png?width=624&amp;table=block&amp;id=2106b074-a1a2-8176-9f33-d761a6cb4cbb" style="width:624px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">I kept track of the average prediction accuracy by the CNN across all four types of errors and it shows that there is a significant drop in prediction accuracy when error probability is low (= 0.1)</span></span></figcaption></figure></div></div><div id="https://www.notion.so/2106b074a1a281f2ac65f84cf970130f" class="Column" style="width:calc((100% - var(--column-spacing) * 1) * 0.5)"><div id="https://www.notion.so/2106b074a1a281d192add5bc62168672" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F4809696d-5a9a-4f6c-a160-40e56fb8823b%2FUntitled.png?width=624&amp;table=block&amp;id=2106b074-a1a2-81d1-92ad-d5bc62168672"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F4809696d-5a9a-4f6c-a160-40e56fb8823b%2FUntitled.png?width=624&amp;table=block&amp;id=2106b074-a1a2-81d1-92ad-d5bc62168672" style="width:624px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Distribution of predictions, showing that when error probability is low (smaller than 0.3), there is a significant number of samples that are incorrectly predicted as &quot;no error‚Äù. </span></span></figcaption></figure></div></div></div><div id="https://www.notion.so/2106b074a1a281d9bb61fa32ad3a7a52" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">To overcome this challenge, I combined the advantages of the classifier, which is more optimal when error probabilities are high, and the workflow without the classifier, where simple algorithms alone are able to produce high accuracy when error probabilities are low. I modified the program where if the CNN predicts the reading trial as ‚Äúno error‚Äù, a simple correction algorithm ‚Äúchain‚Äù will be applied. This significantly improved the final correction accuracy on synthetic dataset.</span></span></p></div><div id="https://www.notion.so/2106b074a1a2811f8e24cb31b0598e80" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fe3685990-0822-476e-98cb-0bf512be69b0%2FUntitled.png?width=432&amp;table=block&amp;id=2106b074-a1a2-811f-8e24-cb31b0598e80"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2Fe3685990-0822-476e-98cb-0bf512be69b0%2FUntitled.png?width=432&amp;table=block&amp;id=2106b074-a1a2-811f-8e24-cb31b0598e80" style="width:432px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Classifier with correction algorithms (improved), showing improved performance in correction with classifier</span></span></figcaption></figure></div><div id="https://www.notion.so/2106b074a1a28103ae80db8ff1d85b1d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">On real data</strong></span></span></p></div><div id="https://www.notion.so/2106b074a1a28163a206de7127fa636a" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">Predictions from the classifier are giving &quot;noise&quot; as the most prominent error in every trial, and therefore, the accuracy of the correction process with classification strictly follows that of the &quot;split&quot; algorithm. My findings reveal that there is not a single algorithm that performs the best among every trial due to the complexity of real data.</span></span></p></div><div id="https://www.notion.so/2106b074a1a28172acecd9e0a0d89bd0" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F60eda7af-e745-4cd6-993b-f6b07ab4d783%2FUntitled.png?width=468&amp;table=block&amp;id=2106b074-a1a2-8172-acec-d9e0a0d89bd0"><img src="https://www.notion.so/signed/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F5afabdf7-d997-4933-9d89-a54b48bd897a%2F60eda7af-e745-4cd6-993b-f6b07ab4d783%2FUntitled.png?width=468&amp;table=block&amp;id=2106b074-a1a2-8172-acec-d9e0a0d89bd0" style="width:468px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">Classifier with correction algorithms on real data</span></span></figcaption></figure></div><h3 id="https://www.notion.so/2106b074a1a281749f45f970e3417794" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--3"><a class="Anchor" href="#https://www.notion.so/2106b074a1a281749f45f970e3417794"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Conclusion and Takeaways</span></span></h3><div id="https://www.notion.so/2106b074a1a28126bc49dcd6f7e079ec" class="Divider"></div><div id="https://www.notion.so/2106b074a1a2814ba55ce882b69c2e3c" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">In this research project, </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">I was able to conduct a full process of controlled experiment</strong></span><span class="SemanticString"> that started from making the innovative approach that coverts eye-tracking data into images and defining the neural networks, to synthetic dataset generation based on the input requirements of the NN-based classifier, then real data collection from human-subject experiments and Golden Set preparation, and eventually to comparative analysis of correction procedures with and without the classification step. My findings consistently show that CNN is an effective approach to classify errors in synthetic eye-tracking data, and is able to improve the correction accuracy by selecting the most optimal algorithm in theory, especially when error probabilities are high, yet its performance on real world data is less optimistic.</span></span></p></div><div id="https://www.notion.so/2106b074a1a281b7a9ade699f15be3b3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">This experience showed me the meaningful impacts of human-centric experiments and how to handle variability in human subjects during research and using algorithms. </strong></span><span class="SemanticString">I was excited by broader applications of my research, as it holds potential for use in clinical studies aimed at assisting patients with reading disorders, thereby enhancing their quality of life. While my approach focused on post-reading correction, machine learning models could be trained to analyze participant&#x27;s reading behaviors in real time and perform the corrections simultaneously, or they can be trained to learn how human correct reading trials and replicate the process. </span></span></p></div></article>
  <footer class="Footer">
  <div>&copy; Hi, I‚Äôm Luhang 2024</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>

</body>

</html>